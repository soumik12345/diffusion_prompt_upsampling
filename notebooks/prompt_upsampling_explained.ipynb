{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMdZcmuim+anRf4Nq+A8jyB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "54b4e444b6da44ca96e9930907d224d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8c176d91dcf42b3ad0c8ba5976bcfd2",
              "IPY_MODEL_3532bce99d8b4135a09eff2604bba2dc",
              "IPY_MODEL_1190cb7afd8e4350a9601397cd2d5576"
            ],
            "layout": "IPY_MODEL_d01a61e9eec6433fb936324fd4ca4c62"
          }
        },
        "a8c176d91dcf42b3ad0c8ba5976bcfd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_592e02874bc740b9abe9081ca9d43548",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bdd9e89da9094477b4a3fada15282e6b",
            "value": "Loadingâ€‡pipelineâ€‡components...:â€‡100%"
          }
        },
        "3532bce99d8b4135a09eff2604bba2dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56d6f86133714d9b8047c031dae2ddbc",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d508d1ac901a4ef2b6aa71dcb79f83c3",
            "value": 7
          }
        },
        "1190cb7afd8e4350a9601397cd2d5576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55b93c70021c4c668dc9852229fcef1c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_eb7513e5349444dba05368f76207e2fc",
            "value": "â€‡7/7â€‡[00:01&lt;00:00,â€‡â€‡3.65it/s]"
          }
        },
        "d01a61e9eec6433fb936324fd4ca4c62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "592e02874bc740b9abe9081ca9d43548": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdd9e89da9094477b4a3fada15282e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56d6f86133714d9b8047c031dae2ddbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d508d1ac901a4ef2b6aa71dcb79f83c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55b93c70021c4c668dc9852229fcef1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb7513e5349444dba05368f76207e2fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa159d9e461048528d9cdd8b3fbd85ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_888d81de4a754110b3401930561271e5",
              "IPY_MODEL_f5d0147a66944801a4ff9ad3cb32104d",
              "IPY_MODEL_f115578114fd44b9bab315c9eed22039"
            ],
            "layout": "IPY_MODEL_e31c0c934f9c44e3ac1ee645638f6469"
          }
        },
        "888d81de4a754110b3401930561271e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b507390218754a9593b05dacf434cbf0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bb22dbd8ad314d85975969af31ac33e1",
            "value": "100%"
          }
        },
        "f5d0147a66944801a4ff9ad3cb32104d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2da5e20f8534cefa7fe1e43c6186d63",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f64c6d7d2db74f3589c2ebe6f0062575",
            "value": 50
          }
        },
        "f115578114fd44b9bab315c9eed22039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c24e59ed8a4f43f79b3eea6d773713e5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8ca3ce293894418bb6b8ecf720b642e7",
            "value": "â€‡50/50â€‡[01:05&lt;00:00,â€‡â€‡1.20it/s]"
          }
        },
        "e31c0c934f9c44e3ac1ee645638f6469": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b507390218754a9593b05dacf434cbf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb22dbd8ad314d85975969af31ac33e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2da5e20f8534cefa7fe1e43c6186d63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f64c6d7d2db74f3589c2ebe6f0062575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c24e59ed8a4f43f79b3eea6d773713e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ca3ce293894418bb6b8ecf720b642e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumik12345/diffusion_prompt_upsampling/blob/main/notebooks/prompt_upsampling_explained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Upsampling for Diffusion Models\n",
        "\n",
        "The secret sauce to getting good-quality images from text-to-image diffusion models is to provide more control conditions. These models are not really \"intelligent,\" if we don't tell them precisely what we want, they won't be able to generate images with many details. One way to achieve this is to **manually write detailed prompts** that give the diffusion model much more context.\n",
        "\n",
        "**Prompt-upsampling** is a process that aims to automate the process of writing a detailed prompt using an LLM. The idea is to develop the most barebone idea for a prompt (such as \"a man holding a sword\") and let a powerful large language model like GPT-4 fill in the prompts with more details, ultimately resulting in a better and more detailed-looking image.\n",
        "\n",
        "You can read a detailed Weights & Biases report on this technique [here](https://wandb.ai/geekyrakshit/prompt-upsampling-diffusion/reports/Prompt-Upsampling-for-Diffusion-Models--Vmlldzo4OTc3NDc3).\n"
      ],
      "metadata": {
        "id": "4wjbjrPLOfUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installations and Initial Setup\n",
        "\n",
        "First, you need to install DSPy, Weave and ðŸ§¨ Diffusers."
      ],
      "metadata": {
        "id": "aXUJxhjLOuJJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSpTwyIqL8D3"
      },
      "outputs": [],
      "source": [
        "!pip install -qU dspy-ai weave diffusers transformers accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we'll be using [OpenAI API](https://openai.com/index/openai-api/) as our LLM Vendor, we will also need an OpenAI API key. You can [sign up](https://platform.openai.com/signup) on the OpenAI platform to get your API key."
      ],
      "metadata": {
        "id": "-V0FBXl7O3gY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "api_key = getpass(\"Enter you OpenAI API key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-nJCRg5cdL8",
        "outputId": "3b78caee-393b-4476-d2f9-17fe4071076a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter you OpenAI API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We write some utility to convert the images into base64 format which would not only let us make multi-modal prompts using the OpenAI API, but also viusalize the images using Weave."
      ],
      "metadata": {
        "id": "sfG2lWQjPGX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import io\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Optional, Union\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "EXT_TO_MIMETYPE = {\n",
        "    \".jpg\": \"image/jpeg\",\n",
        "    \".png\": \"image/png\",\n",
        "    \".svg\": \"image/svg+xml\",\n",
        "}\n",
        "\n",
        "\n",
        "def base64_encode_image(\n",
        "    image_path: Union[str, Image.Image], mimetype: Optional[str] = None\n",
        ") -> str:\n",
        "    image = Image.open(image_path) if isinstance(image_path, str) else image_path\n",
        "    mimetype = (\n",
        "        EXT_TO_MIMETYPE[Path(image_path).suffix]\n",
        "        if isinstance(image_path, str)\n",
        "        else \"image/png\"\n",
        "    )\n",
        "    byte_arr = io.BytesIO()\n",
        "    image.save(byte_arr, format=\"PNG\")\n",
        "    encoded_string = base64.b64encode(byte_arr.getvalue()).decode(\"utf-8\")\n",
        "    encoded_string = f\"data:{mimetype};base64,{encoded_string}\"\n",
        "    return str(encoded_string)\n",
        "\n",
        "\n",
        "def find_base64_images(input_text):\n",
        "    pattern = r\"(data:image/(jpeg|png|svg\\+xml);base64,[A-Za-z0-9+/=]+)\"\n",
        "    return [match[0] for match in re.findall(pattern, input_text)]"
      ],
      "metadata": {
        "id": "vvKlnxnCfulz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we enable tracking using [Weave](https://wandb.me/weave). Weave is integrated with DSPy and including weave.init at the start of our code lets us automatically trace our DSPy functions which can be explored in the Weave UI. Check out the [Weave integration docs for DSPy](https://wandb.github.io/weave/guides/integrations/dspy) to learn more."
      ],
      "metadata": {
        "id": "PdxNVyX_PER0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import weave\n",
        "\n",
        "weave.init(project_name=\"prompt-upsampling-diffusion\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fsjHnnjciXd",
        "outputId": "b78baa24-7392-44e6-cc77-c5280b7acc92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged in as Weights & Biases user: geekyrakshit.\n",
            "View Weave data at https://wandb.ai/geekyrakshit/prompt-upsampling-diffusion/weave\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weave.weave_client.WeaveClient at 0x7dde204aea40>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing Prompt Upsampling using DSPy\n",
        "\n",
        "[DSPy](https://dspy-docs.vercel.app/) is a framework that pushes building new LM pipelines away from manipulating free-form strings and closer to programming (composing modular operators to build text transformation graphs), where a compiler automatically generates optimized LM invocation strategies and prompts from a program.\n",
        "\n",
        "According to the DSPy programming model, string-based prompting techniques are first translated into declarative modules with natural-language typed signatures. Then, each module is parameterized to learn its desired behavior by iteratively bootstrapping useful demonstrations within the pipeline.\n",
        "\n",
        "We're going to use the [`dspy.OpenAI`](https://dspy-docs.vercel.app/api/language_model_clients/OpenAI) abstraction to make LLM calls to [GPT4](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4).\n"
      ],
      "metadata": {
        "id": "VH5LqDWIPqJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dspy\n",
        "\n",
        "\n",
        "upsampler_llm = dspy.OpenAI(\n",
        "    model=\"gpt-4\",\n",
        "    system_prompt=\"\"\"\n",
        "You are part of a team of bots that creates images. You work with an assistant bot that will draw anything\n",
        "you say in square brackets. For example, outputting \"a beautiful morning in the woods with the sun peaking\n",
        "through the trees\" will trigger your partner bot to output an image of a forest morning, as described.\n",
        "You will be prompted by people looking to create detailed, amazing images. The way to accomplish this is to\n",
        "take their short prompts and make them extremely detailed and descriptive.\n",
        "\n",
        "\n",
        "There are a few rules to follow:\n",
        "- You will only ever output a single image description per user request.\n",
        "- Often times, the base prompt might consist of spelling mistakes or grammatical errors. You should correct\n",
        "    such errors before making them extremely detailed and descriptive.\n",
        "- Image descriptions must be between 15-80 words. Extra words will be ignored.\n",
        "\"\"\",\n",
        ")"
      ],
      "metadata": {
        "id": "I5l5LuxFctj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we create a simple signature specifying the input and output behavior of the prompt-upsampling module."
      ],
      "metadata": {
        "id": "8m1MrxJvQBVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PromptUpsamplingSignature(dspy.Signature):\n",
        "    base_prompt = dspy.InputField()\n",
        "    answer = dspy.OutputField(\n",
        "        desc=\"Create an imaginative image descriptive caption for the given base prompt.\"\n",
        "    )"
      ],
      "metadata": {
        "id": "ThlyKuKCcw79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to use [`dspy.MultiChainComparison`](https://dspy-docs.vercel.app/api/modules/MultiChainComparison) Module to execute prompt upsampling. This method aggregates all the student reasoning attempts and calls the `predict` method with extended signatures to get the best reasoning."
      ],
      "metadata": {
        "id": "5KqyW3taQEqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reasoning_attemps = [\n",
        "    dspy.Prediction(\n",
        "        rationale=\"a man holding a sword\",\n",
        "        answer=\"a pale figure with long white hair stands in the center of a dark forest, holding a sword high above his head.\",\n",
        "    ),\n",
        "    dspy.Prediction(\n",
        "        rationale=\"a frog playing dominoes\",\n",
        "        answer=\"a frog sits on a worn table playing a game of dominoes with an elderly raccoon. the table is covered in a green cloth, and the frog is wearing a jacket and a pair of jeans. The scene is set in a forest, with a large tree in the background.\",\n",
        "    ),\n",
        "    dspy.Prediction(\n",
        "        rationale=\"A bird scaring a scarecrow\",\n",
        "        answer=\"A large, vibrant bird with an impressive wingspan swoops down from the sky, letting out a piercing call as it approaches a weathered scarecrow in a sunlit field. The scarecrow, dressed in tattered clothing and a straw hat, appears to tremble, almost as if it's coming to life in fear of the approaching bird.\",\n",
        "    ),\n",
        "    dspy.Prediction(\n",
        "        rationale=\"Paying for a quarter-sized pizza with a pizza-sized quarter\",\n",
        "        answer=\"A person is standing at a pizza counter, holding a gigantic quarter the size of a pizza. The cashier, wide-eyed with astonishment, hands over a tiny, quartersized pizza in return. The background features various pizza toppings and other customers, all of them equally amazed by the unusual transaction.\",\n",
        "    ),\n",
        "    dspy.Prediction(\n",
        "        rationale=\"a quilt with an iron on it\",\n",
        "        answer=\"a quilt is laid out on a ironing board with an iron resting on top. the quilt has a patchwork design with pastel-colored strips of fabric and floral patterns. the iron is turned on and the tip is resting on top of one of the strips. the quilt appears to be in the process of being pressed, as the steam from the iron is visible on the surface. the quilt has a vintage feel and the colors are yellow, blue, and white, giving it an antique look.\",\n",
        "    ),\n",
        "    dspy.Prediction(\n",
        "        rationale=\"a furry humanoid skunk\",\n",
        "        answer=\"In a fantastical setting, a highly detailed furry humanoid skunk with piercing eyes confidently poses in a medium shot, wearing an animal hide jacket. The artist has masterfully rendered the character in digital art, capturing the intricate details of fur and clothing texture.\",\n",
        "    ),\n",
        "    dspy.Prediction(\n",
        "        rationale=\"An icy landscape under a starlit sky\",\n",
        "        answer=\"An icy landscape under a starlit sky, where a magnificent frozen waterfall flows over a cliff. In the center of the scene, a f ire burns bright, its flames seemingly frozen in place, casting a shimmering glow on the surrounding ice and snow.\",\n",
        "    ),\n",
        "    dspy.Prediction(\n",
        "        rationale=\"A fierce garden gnome warrior\",\n",
        "        answer=\"A fierce garden gnome warrior, clad in armor crafted from leaves and bark, brandishes a tiny sword and shield. He stands valiantly on a rock amidst a blooming garden, surrounded by colorful flowers and towering plants. A determined expression is painted on his face, ready to defend his garden kingdom.\",\n",
        "    ),\n",
        "    dspy.Prediction(\n",
        "        rationale=\"A ferret in a candy jar\",\n",
        "        answer=\"A mischievous ferret with a playful grin squeezes itself into a large glass jar, surrounded by colorful candy. The jar sits on a wooden table in a cozy kitchen, and warm sunlight filters through a nearby window.\",\n",
        "    ),\n",
        "    dspy.Prediction(\n",
        "        rationale=\"cartoon drawing of an astronaut riding a horse\",\n",
        "        answer=\"Cartoon drawing of an outer space scene. Amidst floating planets and twinkling stars, a whimsical horse with exaggerated features rides an astronaut, who swims through space with a jetpack, looking a tad overwhelmed.\",\n",
        "    ),\n",
        "    dspy.Prediction(\n",
        "        rationale=\"A smafml vessef epropoeilled on watvewr by ors, sauls, or han engie.\",\n",
        "        answer=\"A small vessel, propelled on water by oars, sails, or an engine, floats gracefully on a serene lake. the sun casts a warm glow on the water, reflecting the vibrant colors of the sky as birds fly overhead.\",\n",
        "    ),\n",
        "]\n"
      ],
      "metadata": {
        "id": "-uwWkkn7c0I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_upsampling_module = dspy.MultiChainComparison(\n",
        "    PromptUpsamplingSignature, M=len(reasoning_attemps)\n",
        ")"
      ],
      "metadata": {
        "id": "eZQVxej2dCfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we wrap the prompt upsampling and subsequent image generation calls using [`weave.Model`](https://wandb.github.io/weave/guides/core-types/models/). A Weave Model combines data (including configuration, trained model weights, or other information) and code defining the model's operation. By structuring your code to be compatible with this API, you benefit from a structured way to version your application so you can more systematically keep track of your experiments."
      ],
      "metadata": {
        "id": "PyPpXQE3QRnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PromptUpsamplingModel(weave.Model):\n",
        "\n",
        "    @weave.op()\n",
        "    def predict(self, base_prompt) -> dict:\n",
        "        with dspy.context(lm=upsampler_llm):\n",
        "            return prompt_upsampling_module(\n",
        "                reasoning_attemps, base_prompt=base_prompt\n",
        "            ).answer"
      ],
      "metadata": {
        "id": "ij_Rvhzad-Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import AutoPipelineForText2Image, DiffusionPipeline\n",
        "\n",
        "\n",
        "class StableDiffusionXLModel(weave.Model):\n",
        "    diffusion_model: str\n",
        "    enable_cpu_offload: bool = True\n",
        "    prompt_upsampler: PromptUpsamplingModel\n",
        "    _pipeline: DiffusionPipeline\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        diffusion_model: str,\n",
        "        enable_cpu_offload: bool,\n",
        "        prompt_upsampler: PromptUpsamplingModel\n",
        "    ):\n",
        "        super().__init__(\n",
        "            diffusion_model=diffusion_model,\n",
        "            enable_cpu_offload=enable_cpu_offload,\n",
        "            prompt_upsampler=prompt_upsampler,\n",
        "        )\n",
        "        self._pipeline = AutoPipelineForText2Image.from_pretrained(\n",
        "            self.diffusion_model,\n",
        "            torch_dtype=torch.float16,\n",
        "            variant=\"fp16\",\n",
        "            use_safetensors=True,\n",
        "        )\n",
        "        if self.enable_cpu_offload:\n",
        "            self._pipeline.enable_model_cpu_offload()\n",
        "        else:\n",
        "            self._pipeline = self._pipeline.to(\"cuda\")\n",
        "\n",
        "    @weave.op()\n",
        "    def predict(\n",
        "        self,\n",
        "        base_prompt: str,\n",
        "        negative_prompt: Optional[str] = None,\n",
        "        num_inference_steps: Optional[int] = 50,\n",
        "        image_size: Optional[int] = 1024,\n",
        "        guidance_scale: Optional[float] = 7.0,\n",
        "    ) -> dict:\n",
        "        upsampled_prompt = self.prompt_upsampler.predict(base_prompt)\n",
        "        image = self._pipeline(\n",
        "            prompt=upsampled_prompt,\n",
        "            negative_prompt=negative_prompt,\n",
        "            num_inference_steps=num_inference_steps,\n",
        "            height=image_size,\n",
        "            width=image_size,\n",
        "            guidance_scale=guidance_scale,\n",
        "        ).images[0]\n",
        "        return {\n",
        "            \"upsampled_prompt\": upsampled_prompt,\n",
        "            \"image\": base64_encode_image(image)\n",
        "        }"
      ],
      "metadata": {
        "id": "l9-LYJXHdJvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_upsampler=PromptUpsamplingModel()\n",
        "\n",
        "model = StableDiffusionXLModel(\n",
        "    diffusion_model=\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    enable_cpu_offload=True,\n",
        "    prompt_upsampler=prompt_upsampler,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "54b4e444b6da44ca96e9930907d224d1",
            "a8c176d91dcf42b3ad0c8ba5976bcfd2",
            "3532bce99d8b4135a09eff2604bba2dc",
            "1190cb7afd8e4350a9601397cd2d5576",
            "d01a61e9eec6433fb936324fd4ca4c62",
            "592e02874bc740b9abe9081ca9d43548",
            "bdd9e89da9094477b4a3fada15282e6b",
            "56d6f86133714d9b8047c031dae2ddbc",
            "d508d1ac901a4ef2b6aa71dcb79f83c3",
            "55b93c70021c4c668dc9852229fcef1c",
            "eb7513e5349444dba05368f76207e2fc"
          ]
        },
        "id": "4dFFCVwQfzNZ",
        "outputId": "a3dc33fd-b6d7-4e21-e856-4c6533998251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54b4e444b6da44ca96e9930907d224d1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sdxl_prediction = model.predict(base_prompt=\"a frog dressed as a knight\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "fa159d9e461048528d9cdd8b3fbd85ef",
            "888d81de4a754110b3401930561271e5",
            "f5d0147a66944801a4ff9ad3cb32104d",
            "f115578114fd44b9bab315c9eed22039",
            "e31c0c934f9c44e3ac1ee645638f6469",
            "b507390218754a9593b05dacf434cbf0",
            "bb22dbd8ad314d85975969af31ac33e1",
            "e2da5e20f8534cefa7fe1e43c6186d63",
            "f64c6d7d2db74f3589c2ebe6f0062575",
            "c24e59ed8a4f43f79b3eea6d773713e5",
            "8ca3ce293894418bb6b8ecf720b642e7"
          ]
        },
        "id": "9tI5OqWfpwvT",
        "outputId": "11070f0a-9577-4ea9-eced-ff7a27bc8c81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (98 > 77). Running this sequence through the model will result in indexing errors\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['bian gaze. this knightly frog is set against a background of lily pads floating on a serene pond.]']\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (98 > 77). Running this sequence through the model will result in indexing errors\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['bian gaze. this knightly frog is set against a background of lily pads floating on a serene pond.]']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa159d9e461048528d9cdd8b3fbd85ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ© https://wandb.ai/geekyrakshit/prompt-upsampling-diffusion/r/call/caafbfbf-2ea7-410c-86ac-80adb561dfe2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a Multi-Modal Evaluation Judge using DSPy\n",
        "\n",
        "Let's also not try to implement an LLM-assisted evaluation strategy to automatically evaluate our generated images for **prompt-following**, i.e., how accurately the generated image follows the corresponding base prompt. To implement this metric, we use a multi-modal LLM like GPT4-O to look at the generated images and the base prompt and ask it to assign a correctness score between 0 and 1 and justify the score with an explanation.\n",
        "\n",
        "### Building a Custom Multi-modal OpenAI Interface for DSPy\n",
        "\n",
        "DSPy doesn't natively support multi-modal prompts. Hence, we first build a custom language model interface called `DSPyOpenAIMultiModalLM` on top of `dsp.GPT3` and implement the logic for interpreting multi-modal prompts. This class can now act as a drop-in replacement for [`dspy.OpenAI`](https://dspy-docs.vercel.app/api/language_model_clients/OpenAI) for multi-modal prompts with [base64 encoded images](https://platform.openai.com/docs/guides/vision/uploading-base-64-encoded-images)."
      ],
      "metadata": {
        "id": "2-MDCy-NQlIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dsp import GPT3\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "class DSPyOpenAIMultiModalLM(GPT3):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: str = \"gpt-4o\",\n",
        "        api_key: str | None = None,\n",
        "        system_prompt: str | None = None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            model,\n",
        "            api_key,\n",
        "            api_provider=\"openai\",\n",
        "            api_base=None,\n",
        "            model_type=None,\n",
        "            system_prompt=system_prompt,\n",
        "            **kwargs,\n",
        "        )\n",
        "        self.model_type = model\n",
        "        self._openai_client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "    @weave.op()\n",
        "    def create_messages(self, prompt: str):\n",
        "        images = find_base64_images(prompt)\n",
        "        for image in images:\n",
        "            prompt = prompt.replace(image, \"\")\n",
        "\n",
        "        user_prompt = [{\"type\": \"text\", \"text\": prompt}]\n",
        "        for image in images:\n",
        "            user_prompt.append({\"type\": \"image_url\", \"image_url\": {\"url\": image}})\n",
        "        messages = []\n",
        "        if self.system_prompt:\n",
        "            messages.append({\"role\": \"system\", \"content\": self.system_prompt})\n",
        "        messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
        "        return messages\n",
        "\n",
        "    @weave.op()\n",
        "    def basic_request(self, prompt: str, **kwargs):\n",
        "        messages = self.create_messages(prompt)\n",
        "        response = self._openai_client.chat.completions.create(\n",
        "            model=self.model_type, messages=messages, **kwargs\n",
        "        )\n",
        "        self.history.append({\"prompt\": prompt, \"response\": response, \"kwargs\": kwargs})\n",
        "        return response\n",
        "\n",
        "    @weave.op()\n",
        "    def request(self, prompt: str, **kwargs):\n",
        "        return super().request(prompt, **kwargs)\n",
        "\n",
        "    @weave.op()\n",
        "    def __call__(\n",
        "        self, prompt: str, only_completed: bool = True, **kwargs\n",
        "    ) -> list:\n",
        "        response = self.request(prompt, **kwargs)\n",
        "        choices = (\n",
        "            [choice for choice in response.choices if choice.finish_reason == \"stop\"]\n",
        "            if only_completed and len(response.choices) != 0\n",
        "            else response.choices\n",
        "        )\n",
        "        return [choice.message.content for choice in choices]"
      ],
      "metadata": {
        "id": "xcZcjHbzvbk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using DSPy Typed Predictors to Ensure Structured Outputs\n",
        "\n",
        "Next, we define the judge module's DSPy signature to structure the inputs and outputs according to a fixed [pydantic](https://docs.pydantic.dev/latest/) schema. When building the predictor for the `JudgeSignature`, we use [`dspy.TypedPredictor`](https://dspy-docs.vercel.app/docs/building-blocks/typed_predictors) that lets us provide the input and parse the output of the module in a structured manner that is consistent with the pydantic schema."
      ],
      "metadata": {
        "id": "6_iZAd9XRB_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class JudgeInput(BaseModel):\n",
        "    base_prompt: str = Field(description=\"The base prompt used to generate the image\")\n",
        "    generated_image: str = Field(description=\"The generated image\")\n",
        "\n",
        "\n",
        "class JudgeMent(BaseModel):\n",
        "    think_out_loud: str = Field(\n",
        "        description=\"Think out loud about your eventual judgement\"\n",
        "    )\n",
        "    score: float = Field(description=\"A score between 0 and 1\")\n",
        "    judgement: str = Field(description=\"Output either 'correct' or 'incorrect'\")\n",
        "\n",
        "\n",
        "class JudgeSignature(dspy.Signature):\n",
        "    input: JudgeInput = dspy.InputField()\n",
        "    output: JudgeMent = dspy.OutputField()\n",
        "\n",
        "\n",
        "class MultiModalJudgeModule(dspy.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.prog = dspy.TypedPredictor(JudgeSignature)\n",
        "\n",
        "    @weave.op()\n",
        "    def forward(self, base_prompt: str, generated_image: str) -> dict:\n",
        "        return self.prog(\n",
        "            input=JudgeInput(\n",
        "                base_prompt=base_prompt, generated_image=generated_image\n",
        "            )\n",
        "        ).output\n",
        "\n",
        "\n",
        "judgement_module = MultiModalJudgeModule()"
      ],
      "metadata": {
        "id": "da7jbk31vnUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the Judge as a Weave Model\n",
        "\n",
        "We will adopt the evaluation prompt from Appendix D of the paper [Improving Image Generation with Better Captions](https://cdn.openai.com/papers/dall-e-3.pdf) as the multi-modal judge's system prompt."
      ],
      "metadata": {
        "id": "aP7HePhCRR6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "JUDGE_SYSTEM_PROMPT = \"\"\"\n",
        "You are responsible for judging the faithfulness of images generated by a computer program to the\n",
        "base prompt used to generate them. You will be presented with an image and given the base prompt\n",
        "that was used to produce the image. The base prompts you are judging are designed to stress-test\n",
        "image generation programs, and may include things such as:\n",
        "1. Scrambled or mis-spelled words (the image generator should an image associated with\n",
        "    the probably meaning).\n",
        "2. Color assignment (the image generator should apply the correct color to the correct object).\n",
        "3. Color assignment (the image generator should apply the correct color to the correct object).\n",
        "4. Abnormal associations, for example 'elephant under a sea', where the image should depict\n",
        "    what is requested.\n",
        "5. Descriptions of objects, the image generator should draw the most commonly associated object.\n",
        "6. Rare single words, where the image generator should create an image somewhat associable with\n",
        "    the specified image.\n",
        "7. Images with text in them, where the image generator should create an image with the specified\n",
        "    text in it. You need to make a decision as to whether or not the image is correct, given the\n",
        "    base prompt.\n",
        "\n",
        "You will first think out loud about your eventual judgement, enumerating reasons why the image\n",
        "does or does not match the given base prompt. After thinking out loud, you should assign a score\n",
        "between 0 and 1 depending on how much you think the image is faithful to the base prompt. Next,\n",
        "you should output either 'correct' or 'incorrect' depending on whether you think the image is\n",
        "faithful to the base prompt.\n",
        "\n",
        "A few rules:\n",
        "1. The score should be used to indicate how close the image is to the base prompt in terms of objects,\n",
        "    color or count; with 0 being very far and 1 being very close.\n",
        "2. If other objects are present in the image that are not explicitly mentioned by the base prompt,\n",
        "    assign a higher score.\n",
        "3. If the objects being displayed is deformed, assign a lower score. Assign a higher score, if the objects\n",
        "    are displayed in a more detailed manner.\n",
        "4. 'incorrect' should be reserved for instances where a specific aspect of the base prompt is not followed\n",
        "    correctly, such as a wrong object, color or count and the score should be less than or equal to 0.5.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "a2c6xNrVv5Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we will write the OpenAI Multi-modal judge as a Weave Model."
      ],
      "metadata": {
        "id": "_az2eKOCRcD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OpenAIJudgeModel(weave.Model):\n",
        "    openai_model: str\n",
        "    seed: int\n",
        "    _judgement_llm: dspy.Module\n",
        "\n",
        "    def __init__(self, openai_model: str = \"gpt-4-turbo\", seed: int = 42):\n",
        "        super().__init__(openai_model=openai_model, seed=seed)\n",
        "        self._judgement_llm = DSPyOpenAIMultiModalLM(\n",
        "            model=\"gpt-4o\", system_prompt=JUDGE_SYSTEM_PROMPT, seed=self.seed\n",
        "        )\n",
        "\n",
        "    @weave.op()\n",
        "    def predict(self, base_prompt: str, generated_image: str) -> JudgeMent:\n",
        "        with dspy.context(lm=self._judgement_llm):\n",
        "            judgement = judgement_module(base_prompt, generated_image)\n",
        "        return judgement\n",
        "\n",
        "    @weave.op()\n",
        "    def score(self, base_prompt: str, model_output: dict) -> dict:\n",
        "        judgement: JudgeMent = self.predict(\n",
        "            base_prompt=base_prompt, generated_image=model_output[\"image\"]\n",
        "        )\n",
        "        return {\n",
        "            \"score\": judgement.score,\n",
        "            \"is_image_correct\": judgement.judgement == \"correct\",\n",
        "        }"
      ],
      "metadata": {
        "id": "6XGXEQ2Dv77N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "judge_model = OpenAIJudgeModel()\n",
        "judgement = judge_model.score(\"a frog dressed as a knight\", sdxl_prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N80l10LhwPOX",
        "outputId": "bdbaf19c-4791-4bdd-db70-5c36c97c0bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ© https://wandb.ai/geekyrakshit/prompt-upsampling-diffusion/r/call/f65464b2-b86d-4e0b-a81b-e0fa7b65ff60\n"
          ]
        }
      ]
    }
  ]
}